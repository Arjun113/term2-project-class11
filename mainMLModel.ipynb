{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5cf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mplib\n",
    "import seaborn as sborn\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb8baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  object \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  object \n",
      " 16  Weekend                  12330 non-null  bool   \n",
      " 17  Revenue                  12330 non-null  bool   \n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "      <td>12330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.315166</td>\n",
       "      <td>80.818611</td>\n",
       "      <td>0.503569</td>\n",
       "      <td>34.472398</td>\n",
       "      <td>31.731468</td>\n",
       "      <td>1194.746220</td>\n",
       "      <td>0.022191</td>\n",
       "      <td>0.043073</td>\n",
       "      <td>5.889258</td>\n",
       "      <td>0.061427</td>\n",
       "      <td>2.124006</td>\n",
       "      <td>2.357097</td>\n",
       "      <td>3.147364</td>\n",
       "      <td>4.069586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.321784</td>\n",
       "      <td>176.779107</td>\n",
       "      <td>1.270156</td>\n",
       "      <td>140.749294</td>\n",
       "      <td>44.475503</td>\n",
       "      <td>1913.669288</td>\n",
       "      <td>0.048488</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>18.568437</td>\n",
       "      <td>0.198917</td>\n",
       "      <td>0.911325</td>\n",
       "      <td>1.717277</td>\n",
       "      <td>2.401591</td>\n",
       "      <td>4.025169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>184.137500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>598.936905</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.025156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>93.256250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1464.157214</td>\n",
       "      <td>0.016813</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>3398.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2549.375000</td>\n",
       "      <td>705.000000</td>\n",
       "      <td>63973.522230</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>361.763742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Administrative  Administrative_Duration  Informational  \\\n",
       "count    12330.000000             12330.000000   12330.000000   \n",
       "mean         2.315166                80.818611       0.503569   \n",
       "std          3.321784               176.779107       1.270156   \n",
       "min          0.000000                 0.000000       0.000000   \n",
       "25%          0.000000                 0.000000       0.000000   \n",
       "50%          1.000000                 7.500000       0.000000   \n",
       "75%          4.000000                93.256250       0.000000   \n",
       "max         27.000000              3398.750000      24.000000   \n",
       "\n",
       "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "count            12330.000000    12330.000000             12330.000000   \n",
       "mean                34.472398       31.731468              1194.746220   \n",
       "std                140.749294       44.475503              1913.669288   \n",
       "min                  0.000000        0.000000                 0.000000   \n",
       "25%                  0.000000        7.000000               184.137500   \n",
       "50%                  0.000000       18.000000               598.936905   \n",
       "75%                  0.000000       38.000000              1464.157214   \n",
       "max               2549.375000      705.000000             63973.522230   \n",
       "\n",
       "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
       "count  12330.000000  12330.000000  12330.000000  12330.000000   \n",
       "mean       0.022191      0.043073      5.889258      0.061427   \n",
       "std        0.048488      0.048597     18.568437      0.198917   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.014286      0.000000      0.000000   \n",
       "50%        0.003112      0.025156      0.000000      0.000000   \n",
       "75%        0.016813      0.050000      0.000000      0.000000   \n",
       "max        0.200000      0.200000    361.763742      1.000000   \n",
       "\n",
       "       OperatingSystems       Browser        Region   TrafficType  \n",
       "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
       "mean           2.124006      2.357097      3.147364      4.069586  \n",
       "std            0.911325      1.717277      2.401591      4.025169  \n",
       "min            1.000000      1.000000      1.000000      1.000000  \n",
       "25%            2.000000      2.000000      1.000000      2.000000  \n",
       "50%            2.000000      2.000000      3.000000      2.000000  \n",
       "75%            3.000000      2.000000      4.000000      4.000000  \n",
       "max            8.000000     13.000000      9.000000     20.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the data\n",
    "\n",
    "dataframe = pd.read_csv(\"Data.csv\")\n",
    "dataframe.info()\n",
    "dataframe.head(20)\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad41cb7",
   "metadata": {},
   "source": [
    "There seem to be no missing data fields here, I think we can move on to the main part of the code: the modelling and creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32ce8aa",
   "metadata": {},
   "source": [
    "But before that, we need to figure out some stats for the information contained in the csv file, as well as convert the names of the months into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06f9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5768\n",
      "1     1354\n",
      "2     1114\n",
      "3      915\n",
      "4      765\n",
      "5      575\n",
      "6      432\n",
      "7      338\n",
      "8      287\n",
      "9      225\n",
      "10     153\n",
      "11     105\n",
      "12      86\n",
      "13      56\n",
      "14      44\n",
      "15      38\n",
      "16      24\n",
      "17      16\n",
      "18      12\n",
      "19       6\n",
      "24       4\n",
      "22       4\n",
      "23       3\n",
      "21       2\n",
      "20       2\n",
      "27       1\n",
      "26       1\n",
      "Name: Administrative, dtype: int64\n",
      "0.000000      5903\n",
      "4.000000        56\n",
      "5.000000        53\n",
      "7.000000        45\n",
      "11.000000       42\n",
      "              ... \n",
      "68.014286        1\n",
      "362.300000       1\n",
      "90.700000        1\n",
      "760.900000       1\n",
      "150.357143       1\n",
      "Name: Administrative_Duration, Length: 3335, dtype: int64\n",
      "0     9699\n",
      "1     1041\n",
      "2      728\n",
      "3      380\n",
      "4      222\n",
      "5       99\n",
      "6       78\n",
      "7       36\n",
      "9       15\n",
      "8       14\n",
      "10       7\n",
      "12       5\n",
      "14       2\n",
      "16       1\n",
      "11       1\n",
      "24       1\n",
      "13       1\n",
      "Name: Informational, dtype: int64\n",
      "0.00      9925\n",
      "9.00        33\n",
      "7.00        26\n",
      "10.00       26\n",
      "6.00        26\n",
      "          ... \n",
      "246.80       1\n",
      "274.00       1\n",
      "13.40        1\n",
      "223.15       1\n",
      "211.25       1\n",
      "Name: Informational_Duration, Length: 1258, dtype: int64\n",
      "1      622\n",
      "2      465\n",
      "3      458\n",
      "4      404\n",
      "6      396\n",
      "      ... \n",
      "243      1\n",
      "409      1\n",
      "262      1\n",
      "414      1\n",
      "192      1\n",
      "Name: ProductRelated, Length: 311, dtype: int64\n",
      "0.000000      755\n",
      "17.000000      21\n",
      "11.000000      17\n",
      "8.000000       17\n",
      "15.000000      16\n",
      "             ... \n",
      "964.070513      1\n",
      "593.507143      1\n",
      "831.388889      1\n",
      "922.208333      1\n",
      "346.000000      1\n",
      "Name: ProductRelated_Duration, Length: 9551, dtype: int64\n",
      "0.000000    5518\n",
      "0.200000     700\n",
      "0.066667     134\n",
      "0.028571     115\n",
      "0.050000     113\n",
      "            ... \n",
      "0.079279       1\n",
      "0.006723       1\n",
      "0.013527       1\n",
      "0.074419       1\n",
      "0.011149       1\n",
      "Name: BounceRates, Length: 1872, dtype: int64\n",
      "0.200000    710\n",
      "0.100000    338\n",
      "0.050000    329\n",
      "0.033333    291\n",
      "0.066667    267\n",
      "           ... \n",
      "0.021816      1\n",
      "0.015787      1\n",
      "0.010302      1\n",
      "0.014534      1\n",
      "0.029031      1\n",
      "Name: ExitRates, Length: 4777, dtype: int64\n",
      "0.000000     9600\n",
      "53.988000       6\n",
      "42.293068       3\n",
      "59.988000       2\n",
      "16.158558       2\n",
      "             ... \n",
      "6.673696        1\n",
      "6.094324        1\n",
      "28.253955       1\n",
      "16.090650       1\n",
      "12.241717       1\n",
      "Name: PageValues, Length: 2704, dtype: int64\n",
      "0.0    11079\n",
      "0.6      351\n",
      "0.8      325\n",
      "0.4      243\n",
      "0.2      178\n",
      "1.0      154\n",
      "Name: SpecialDay, dtype: int64\n",
      "May     3364\n",
      "Nov     2998\n",
      "Mar     1907\n",
      "Dec     1727\n",
      "Oct      549\n",
      "Sep      448\n",
      "Aug      433\n",
      "Jul      432\n",
      "June     288\n",
      "Feb      184\n",
      "Name: Month, dtype: int64\n",
      "2    6601\n",
      "1    2585\n",
      "3    2555\n",
      "4     478\n",
      "8      79\n",
      "6      19\n",
      "7       7\n",
      "5       6\n",
      "Name: OperatingSystems, dtype: int64\n",
      "2     7961\n",
      "1     2462\n",
      "4      736\n",
      "5      467\n",
      "6      174\n",
      "10     163\n",
      "8      135\n",
      "3      105\n",
      "13      61\n",
      "7       49\n",
      "12      10\n",
      "11       6\n",
      "9        1\n",
      "Name: Browser, dtype: int64\n",
      "1    4780\n",
      "3    2403\n",
      "4    1182\n",
      "2    1136\n",
      "6     805\n",
      "7     761\n",
      "9     511\n",
      "8     434\n",
      "5     318\n",
      "Name: Region, dtype: int64\n",
      "2     3913\n",
      "1     2451\n",
      "3     2052\n",
      "4     1069\n",
      "13     738\n",
      "10     450\n",
      "6      444\n",
      "8      343\n",
      "5      260\n",
      "11     247\n",
      "20     198\n",
      "9       42\n",
      "7       40\n",
      "15      38\n",
      "19      17\n",
      "14      13\n",
      "18      10\n",
      "16       3\n",
      "12       1\n",
      "17       1\n",
      "Name: TrafficType, dtype: int64\n",
      "Returning_Visitor    10551\n",
      "New_Visitor           1694\n",
      "Other                   85\n",
      "Name: VisitorType, dtype: int64\n",
      "False    9462\n",
      "True     2868\n",
      "Name: Weekend, dtype: int64\n",
      "False    10422\n",
      "True      1908\n",
      "Name: Revenue, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#printing value counts for each column\n",
    "print(dataframe['Administrative'].value_counts())\n",
    "print(dataframe[\"Administrative_Duration\"].value_counts())\n",
    "print(dataframe['Informational'].value_counts())\n",
    "print(dataframe['Informational_Duration'].value_counts())\n",
    "print(dataframe['ProductRelated'].value_counts())\n",
    "print(dataframe['ProductRelated_Duration'].value_counts())\n",
    "print(dataframe['BounceRates'].value_counts())\n",
    "print(dataframe['ExitRates'].value_counts())\n",
    "print(dataframe['PageValues'].value_counts())\n",
    "print(dataframe['SpecialDay'].value_counts())\n",
    "print(dataframe['Month'].value_counts())\n",
    "print(dataframe['OperatingSystems'].value_counts())\n",
    "print(dataframe['Browser'].value_counts())\n",
    "print(dataframe['Region'].value_counts())\n",
    "print(dataframe['TrafficType'].value_counts())\n",
    "print(dataframe['VisitorType'].value_counts())\n",
    "print(dataframe['Weekend'].value_counts())\n",
    "print(dataframe['Revenue'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735ccafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  int64  \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  int64  \n",
      " 16  Weekend                  12330 non-null  int64  \n",
      " 17  Revenue                  12330 non-null  int64  \n",
      "dtypes: float64(7), int64(11)\n",
      "memory usage: 1.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0      2                 1   \n",
       "1         0.00       0.10         0.0         0.0      2                 2   \n",
       "2         0.20       0.20         0.0         0.0      2                 4   \n",
       "3         0.05       0.14         0.0         0.0      2                 3   \n",
       "4         0.02       0.05         0.0         0.0      2                 3   \n",
       "\n",
       "   Browser  Region  TrafficType  VisitorType  Weekend  Revenue  \n",
       "0        1       1            1            1        0        0  \n",
       "1        2       1            2            1        0        0  \n",
       "2        1       9            3            1        0        0  \n",
       "3        2       2            4            1        0        0  \n",
       "4        3       1            4            1        1        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = {\"Month\": {\"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6, \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12}, \"VisitorType\": {\"New_Visitor\": 0, \"Returning_Visitor\": 1, \"Other\": 2}, \"Weekend\": {True: 1, False: 0}, \"Revenue\": {True: 1, False: 0}}\n",
    "dataframe_labelencoded = dataframe.copy()\n",
    "dataframe_labelencoded.replace(label_encode, inplace = True, regex = True)\n",
    "dataframe_labelencoded.info()\n",
    "dataframe_labelencoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe725da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataframe_labelencoded[\"Revenue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019c3faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAO7klEQVR4nO3db2xdd33H8feHpFUGlJWlBkGcLZkU/kSIAvNKt2kbWwIkBZFN2oMWBqxDiiq1jE2T1qJpGxLStGl/xBCFKOqygobIA+hGhgIFuj88YJ3qMFYaQsEqo7mkW92ysQlUtaHfPbg3zLWvfa/bax/88/slWfE555d7vsdO3zq+9q1TVUiSNr6ndT2AJGkyDLokNcKgS1IjDLokNcKgS1IjtnZ14ssuu6x27drV1eklaUM6derUQ1U1NexYZ0HftWsXs7OzXZ1ekjakJN9Y7phPuUhSIwy6JDXCoEtSIzp7Dl2SNrvHHnuMXq/HI488suTYtm3bmJ6e5qKLLhr78Qy6JHWk1+txySWXsGvXLpJ8f39V8fDDD9Pr9di9e/fYjzfyKZckx5I8mOSeZY4nyXuTzCW5O8krxj77au3fD8n/v+3fv2anWmLheS+8ta6ra+7yY73ZrtmPdafX/MiZM2zfvv0JMe8vC9u3bx96576ScZ5DvxU4sMLxg8Cewdth4AOrmmBc+/fDHXc8cd8dd6xP1Jf7hLcc9a6uucuP9Wa7Zj/W63fe5c7xtKeRU6eWWb76mUYGvao+B3xrhSWHgA9V353ApUmet+pJRlkc81H7JWmTmcRPuewAzi7Y7g32LZHkcJLZJLPz8/MTOLUk6YJJBH3Y1wVDf2tGVR2tqpmqmpmaGvrKVUnaPB5/fHgs6X9jdLUmEfQesHPB9jRwbgKP+0T79q1uvyT9gNs2N8fD588vifeFn3LZtm3bqh5vEj+2eAK4Iclx4JXAt6vqgQk87hN99rNLvzG6b19//1qrGv4NjZZ/fV9X19zlx3qzXbMf6/U77zLnnn7Xu+idOsX8V76yZPmFn0NfjZFBT/IR4FXAZUl6wB8AF/XnqyPASeAqYA74LnDtqiZYjfWI93JajvdyurrmLj/Wm+2a/Vh3eu6LgPF/yny0kUGvqmtGHC/g+olNJEl6Uvx/uUhSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSI8YKepIDSe5NMpfkpiHHfzjJ3yX5tySnk1w7+VElSSsZGfQkW4CbgYPAXuCaJHsXLbse+HJVXQ68CvizJBdPeFZJ0grGuUO/Apirqvuq6lHgOHBo0ZoCLkkS4JnAt4DzE51UkrSicYK+Azi7YLs32LfQ+4AXA+eALwHvqKrHFz9QksNJZpPMzs/PP8mRJUnDjBP0DNlXi7ZfC3wReD7wMuB9SZ615C9VHa2qmaqamZqaWuWokqSVjBP0HrBzwfY0/Tvxha4Fbqu+OeDrwIsmM6IkaRzjBP0uYE+S3YNvdF4NnFi05n5gH0CS5wIvBO6b5KCSpJVtHbWgqs4nuQG4HdgCHKuq00muGxw/ArwbuDXJl+g/RXNjVT20hnNLkhYZGXSAqjoJnFy078iC988Br5nsaJKk1fCVopLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0w6JLUCIMuSY0YK+hJDiS5N8lckpuWWfOqJF9McjrJP012TEnSKFtHLUiyBbgZeDXQA+5KcqKqvrxgzaXA+4EDVXV/kues0bySpGWMc4d+BTBXVfdV1aPAceDQojVvBG6rqvsBqurByY4pSRplnKDvAM4u2O4N9i30AuDZSf4xyakkbxn2QEkOJ5lNMjs/P//kJpYkDTVO0DNkXy3a3gr8BPA64LXA7yV5wZK/VHW0qmaqamZqamrVw0qSljfyOXT6d+Q7F2xPA+eGrHmoqr4DfCfJ54DLga9OZEpJ0kjj3KHfBexJsjvJxcDVwIlFaz4O/GySrUmeDrwSODPZUSVJKxl5h15V55PcANwObAGOVdXpJNcNjh+pqjNJPgXcDTwO3FJV96zl4JKkJ0rV4qfD18fMzEzNzs52cm5J2qiSnKqqmWHHfKWoJDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDVirKAnOZDk3iRzSW5aYd1PJvlekl+Z3IiSpHGMDHqSLcDNwEFgL3BNkr3LrPtj4PZJDylJGm2cO/QrgLmquq+qHgWOA4eGrHs78DHgwQnOJ0ka0zhB3wGcXbDdG+z7viQ7gF8Gjqz0QEkOJ5lNMjs/P7/aWSVJKxgn6BmyrxZtvwe4saq+t9IDVdXRqpqpqpmpqakxR5QkjWPrGGt6wM4F29PAuUVrZoDjSQAuA65Kcr6q/nYSQ0qSRhsn6HcBe5LsBr4JXA28ceGCqtp94f0ktwKfMOaStL5GBr2qzie5gf5Pr2wBjlXV6STXDY6v+Ly5JGl9jHOHTlWdBE4u2jc05FX1a099LEnSavlKUUlqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEaMFfQkB5Lcm2QuyU1Djr8pyd2Dt88nuXzyo0qSVjIy6Em2ADcDB4G9wDVJ9i5a9nXg56vqpcC7gaOTHlSStLJx7tCvAOaq6r6qehQ4DhxauKCqPl9V/zXYvBOYnuyYkqRRxgn6DuDsgu3eYN9y3gZ8ctiBJIeTzCaZnZ+fH39KSdJI4wQ9Q/bV0IXJL9AP+o3DjlfV0aqaqaqZqamp8aeUJI20dYw1PWDngu1p4NziRUleCtwCHKyqhyczniRpXOPcod8F7EmyO8nFwNXAiYULkvwocBvw5qr66uTHlCSNMvIOvarOJ7kBuB3YAhyrqtNJrhscPwL8PrAdeH8SgPNVNbN2Y0uSFkvV0KfD19zMzEzNzs52cm5J2qiSnFruhtlXikpSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSI8YKepIDSe5NMpfkpiHHk+S9g+N3J3nF5EcFkqVv66XLc3elq2vejJ/nzXbeLs/d8DWPDHqSLcDNwEFgL3BNkr2Llh0E9gzeDgMfmOiU/UFWt7+Vc3elq2vejJ/nzXbeLs/d+DWPc4d+BTBXVfdV1aPAceDQojWHgA9V353ApUmeN7EpJUkjjRP0HcDZBdu9wb7VriHJ4SSzSWbn5+dXO6skaQXjBH3Y1wP1JNZQVUeraqaqZqampsaZT5I0pnGC3gN2LtieBs49iTWSpDU0TtDvAvYk2Z3kYuBq4MSiNSeAtwx+2uVK4NtV9cBEJ60lN/wr72/l3F3p6po34+d5s523y3M3fs1bR89Q55PcANwObAGOVdXpJNcNjh8BTgJXAXPAd4FrJzbhE4dZk4f9gT93V7q65s34ed5s5+3y3A1f88ig92eok/SjvXDfkQXvF3D9ZEeTJK2GrxSVpEYYdElqhEGXpEYYdElqRKqj7/gmmQe+8ST/+mXAQxMcZyPwmjcHr3lzeCrX/GNVNfSVmZ0F/alIMltVM13PsZ685s3Ba94c1uqafcpFkhph0CWpERs16Ee7HqADXvPm4DVvDmtyzRvyOXRJ0lIb9Q5dkrSIQZekRmyooCfZmeQfkpxJcjrJO7qeab0k2ZLkX5N8outZ1kOSS5N8NMlXBp/vn+p6prWU5LcG/6bvSfKRJNu6nmktJDmW5MEk9yzY9yNJPpPka4M/n93ljJO2zDX/yeDf9t1J/ibJpZM414YKOnAe+O2qejFwJXD9kF9Y3ap3AGe6HmId/QXwqap6EXA5DV97kh3AbwAzVfUS+v+b6qu7nWrN3AocWLTvJuCOqtoD3DHYbsmtLL3mzwAvqaqXAl8F3jmJE22ooFfVA1X1hcH7/0v/P/Ilv7u0NUmmgdcBt3Q9y3pI8izg54C/BKiqR6vqvzsdau1tBX4oyVbg6TT6G7+q6nPAtxbtPgR8cPD+B4FfWs+Z1tqwa66qT1fV+cHmnfR/y9tTtqGCvlCSXcDLgX/peJT18B7gd4DHO55jvfw4MA/81eBppluSPKProdZKVX0T+FPgfuAB+r/x69PdTrWunnvhN5wN/nxOx/Ost18HPjmJB9qQQU/yTOBjwG9W1f90Pc9aSvJ64MGqOtX1LOtoK/AK4ANV9XLgO7T3Zfj3DZ4zPgTsBp4PPCPJr3Y7ldZDkt+l/1TyhyfxeBsu6Ekuoh/zD1fVbV3Psw5+BnhDkn8HjgO/mOSvux1pzfWAXlVd+Orro/QD36r9wNerar6qHgNuA36645nW038meR7A4M8HO55nXSR5K/B64E01oRcEbaigJwn951XPVNWfdz3Peqiqd1bVdFXtov+Nsr+vqqbv3qrqP4CzSV442LUP+HKHI621+4Erkzx98G98Hw1/E3iIE8BbB++/Ffh4h7OsiyQHgBuBN1TVdyf1uBsq6PTvVt9M/y71i4O3q7oeSmvi7cCHk9wNvAz4w27HWTuDr0Q+CnwB+BL9/y6bfDl8ko8A/wy8MEkvyduAPwJeneRrwKsH281Y5prfB1wCfGbQsSMrPsi45/Kl/5LUho12hy5JWoZBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJasT/AdbK/Yt+ZbZuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataframe_labelencoded[\"Month\"]\n",
    "mplib.scatter(x, y, color = \"Red\")\n",
    "mplib.legend()\n",
    "mplib.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe988f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dataframe_labelencoded[\"OperatingSystems\"]\n",
    "mplib.scatter(x, y, color = \"Red\", alpha = 0.01)\n",
    "mplib.legend()\n",
    "mplib.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d3adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "12325    0\n",
      "12326    0\n",
      "12327    0\n",
      "12328    0\n",
      "12329    0\n",
      "Name: Revenue, Length: 12330, dtype: int64\n",
      "       Administrative  Administrative_Duration  Informational  \\\n",
      "0                   0                      0.0              0   \n",
      "1                   0                      0.0              0   \n",
      "2                   0                      0.0              0   \n",
      "3                   0                      0.0              0   \n",
      "4                   0                      0.0              0   \n",
      "...               ...                      ...            ...   \n",
      "12325               3                    145.0              0   \n",
      "12326               0                      0.0              0   \n",
      "12327               0                      0.0              0   \n",
      "12328               4                     75.0              0   \n",
      "12329               0                      0.0              0   \n",
      "\n",
      "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "0                         0.0               1                 0.000000   \n",
      "1                         0.0               2                64.000000   \n",
      "2                         0.0               1                 0.000000   \n",
      "3                         0.0               2                 2.666667   \n",
      "4                         0.0              10               627.500000   \n",
      "...                       ...             ...                      ...   \n",
      "12325                     0.0              53              1783.791667   \n",
      "12326                     0.0               5               465.750000   \n",
      "12327                     0.0               6               184.250000   \n",
      "12328                     0.0              15               346.000000   \n",
      "12329                     0.0               3                21.250000   \n",
      "\n",
      "       BounceRates  ExitRates  PageValues  SpecialDay  Month  \\\n",
      "0         0.200000   0.200000    0.000000         0.0      2   \n",
      "1         0.000000   0.100000    0.000000         0.0      2   \n",
      "2         0.200000   0.200000    0.000000         0.0      2   \n",
      "3         0.050000   0.140000    0.000000         0.0      2   \n",
      "4         0.020000   0.050000    0.000000         0.0      2   \n",
      "...            ...        ...         ...         ...    ...   \n",
      "12325     0.007143   0.029031   12.241717         0.0     12   \n",
      "12326     0.000000   0.021333    0.000000         0.0     11   \n",
      "12327     0.083333   0.086667    0.000000         0.0     11   \n",
      "12328     0.000000   0.021053    0.000000         0.0     11   \n",
      "12329     0.000000   0.066667    0.000000         0.0     11   \n",
      "\n",
      "       OperatingSystems  Browser  Region  TrafficType  VisitorType  Weekend  \n",
      "0                     1        1       1            1            1        0  \n",
      "1                     2        2       1            2            1        0  \n",
      "2                     4        1       9            3            1        0  \n",
      "3                     3        2       2            4            1        0  \n",
      "4                     3        3       1            4            1        1  \n",
      "...                 ...      ...     ...          ...          ...      ...  \n",
      "12325                 4        6       1            1            1        1  \n",
      "12326                 3        2       1            8            1        1  \n",
      "12327                 3        2       1           13            1        1  \n",
      "12328                 2        2       3           11            1        0  \n",
      "12329                 3        2       1            2            0        1  \n",
      "\n",
      "[12330 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "x_values = dataframe_labelencoded.drop([\"Revenue\"], axis = 1)\n",
    "y_values = dataframe_labelencoded[\"Revenue\"]\n",
    "print(y_values) #Testing only, again\n",
    "print(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9511209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       12330 non-null  float64\n",
      " 1   1       12330 non-null  float64\n",
      " 2   2       12330 non-null  float64\n",
      " 3   3       12330 non-null  float64\n",
      " 4   4       12330 non-null  float64\n",
      " 5   5       12330 non-null  float64\n",
      " 6   6       12330 non-null  float64\n",
      " 7   7       12330 non-null  float64\n",
      " 8   8       12330 non-null  float64\n",
      " 9   9       12330 non-null  float64\n",
      " 10  10      12330 non-null  float64\n",
      " 11  11      12330 non-null  float64\n",
      " 12  12      12330 non-null  float64\n",
      " 13  13      12330 non-null  float64\n",
      " 14  14      12330 non-null  float64\n",
      " 15  15      12330 non-null  float64\n",
      " 16  16      12330 non-null  float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "#standardisation.....\n",
    "Standardise = StandardScaler()\n",
    "x_values_standardised = Standardise.fit_transform(x_values)\n",
    "x_values_dataframe = pd.DataFrame(x_values_standardised)\n",
    "x_values_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad0cdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Administrative  Administrative_Duration  Informational  \\\n",
      "10350               5               613.500000              0   \n",
      "11646               3                13.333333              4   \n",
      "8865                0                 0.000000              0   \n",
      "2683                0                 0.000000              0   \n",
      "5634                5               148.500000              0   \n",
      "...               ...                      ...            ...   \n",
      "3046                0                 0.000000              0   \n",
      "9917                0                 0.000000              0   \n",
      "4079                0                 0.000000              0   \n",
      "2254                3                77.000000              5   \n",
      "2915                0                 0.000000              0   \n",
      "\n",
      "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "10350                     0.0             470               14129.8808   \n",
      "11646                    68.5              72                1602.3500   \n",
      "8865                      0.0               3                  15.0000   \n",
      "2683                      0.0               0                   0.0000   \n",
      "5634                      0.0              25                 307.7000   \n",
      "...                       ...             ...                      ...   \n",
      "3046                      0.0              44                 547.0000   \n",
      "9917                      0.0               2                  11.0000   \n",
      "4079                      0.0               3                   9.0000   \n",
      "2254                    243.0             127                2573.8750   \n",
      "2915                      0.0              11                 276.0000   \n",
      "\n",
      "       BounceRates  ExitRates  PageValues  SpecialDay  Month  \\\n",
      "10350     0.000000   0.003621   13.381494         0.0     11   \n",
      "11646     0.002747   0.038988    0.000000         0.0     11   \n",
      "8865      0.066667   0.133333    0.000000         0.0     11   \n",
      "2683      0.200000   0.200000    0.000000         0.0      5   \n",
      "5634      0.007692   0.034615    0.000000         0.0     10   \n",
      "...            ...        ...         ...         ...    ...   \n",
      "3046      0.060000   0.087407    0.000000         0.6      5   \n",
      "9917      0.000000   0.100000    0.000000         0.0     11   \n",
      "4079      0.066667   0.133333    0.000000         0.0      5   \n",
      "2254      0.000256   0.009197    0.000000         0.0      5   \n",
      "2915      0.000000   0.011111    0.000000         0.0      5   \n",
      "\n",
      "       OperatingSystems  Browser  Region  TrafficType  VisitorType  Weekend  \n",
      "10350                 4        2       9            2            1        1  \n",
      "11646                 2        2       3            2            1        0  \n",
      "8865                  2        2       1            3            1        0  \n",
      "2683                  3        2       3           18            1        1  \n",
      "5634                  4        1       9            3            1        1  \n",
      "...                 ...      ...     ...          ...          ...      ...  \n",
      "3046                  3        2       1           13            1        0  \n",
      "9917                  3        2       1           10            1        0  \n",
      "4079                  2        2       2            3            1        1  \n",
      "2254                  2        2       4            3            1        0  \n",
      "2915                  2        2       1            1            1        0  \n",
      "\n",
      "[8631 rows x 17 columns]\n",
      "10350    1\n",
      "11646    0\n",
      "8865     0\n",
      "2683     0\n",
      "5634     0\n",
      "        ..\n",
      "3046     0\n",
      "9917     0\n",
      "4079     0\n",
      "2254     0\n",
      "2915     0\n",
      "Name: Revenue, Length: 8631, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size = 0.3, random_state = 5)\n",
    "print(x_train) #Testing\n",
    "print(y_train) #Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbfe0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.80656857  3.09142407 -0.39801287 ... -0.51672961  0.36483731\n",
      "   1.80267322]\n",
      " [ 0.20287492 -0.38779636  2.73562367 ... -0.51672961  0.36483731\n",
      "  -0.55473171]\n",
      " [-0.70266556 -0.46509089 -0.39801287 ... -0.26656732  0.36483731\n",
      "  -0.55473171]\n",
      " ...\n",
      " [-0.70266556 -0.46509089 -0.39801287 ... -0.26656732  0.36483731\n",
      "   1.80267322]\n",
      " [ 0.20287492 -0.01871493  3.5190328  ... -0.26656732  0.36483731\n",
      "  -0.55473171]\n",
      " [-0.70266556 -0.46509089 -0.39801287 ... -0.7668919   0.36483731\n",
      "  -0.55473171]]\n",
      "-------------GAP----------\n",
      "[[-0.70266556 -0.46509089 -0.39801287 ... -0.7668919   0.36483731\n",
      "  -0.55473171]\n",
      " [-0.70266556 -0.46509089 -0.39801287 ... -0.7668919   0.36483731\n",
      "   1.80267322]\n",
      " [-0.70266556 -0.46509089 -0.39801287 ...  1.4845687   0.36483731\n",
      "  -0.55473171]\n",
      " ...\n",
      " [ 0.20287492  0.0218647  -0.39801287 ... -0.7668919   0.36483731\n",
      "  -0.55473171]\n",
      " [ 1.1084154  -0.09939111 -0.39801287 ... -0.51672961  0.36483731\n",
      "  -0.55473171]\n",
      " [-0.40081873 -0.44190253 -0.39801287 ... -0.7668919   0.36483731\n",
      "  -0.55473171]]\n"
     ]
    }
   ],
   "source": [
    "#Standardisation, yet again\n",
    "x_train_scale = Standardise.fit_transform(x_train)\n",
    "x_test_scale = Standardise.transform(x_test)\n",
    "print(x_train_scale)\n",
    "print(\"-------------GAP----------\") #I'm human, I need to see some separation...\n",
    "print(x_test_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624dec5d",
   "metadata": {},
   "source": [
    "TensorFlow and Keras starts here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7a37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(17, activation = \"relu\", input_dim = 17))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Hidden layer 2\n",
    "model.add(Dense(17, activation = \"relu\"))\n",
    "#Output layer\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "#COmpilation\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55a0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 17)                306       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 17)                306       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 17)                306       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,850\n",
      "Trainable params: 5,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Checking for correct compilation\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b017e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Had to do onehot encoding in any case....\n",
    "y_train_onehot = to_categorical(y_train)\n",
    "y_test_onehot = to_categorical(y_test)\n",
    "print(y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50fe8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "270/270 [==============================] - 1s 718us/step - loss: 0.3532 - accuracy: 0.8612\n",
      "Epoch 2/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2846 - accuracy: 0.8911\n",
      "Epoch 3/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2715 - accuracy: 0.8938\n",
      "Epoch 4/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.2643 - accuracy: 0.8954\n",
      "Epoch 5/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2588 - accuracy: 0.8967\n",
      "Epoch 6/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2548 - accuracy: 0.8973\n",
      "Epoch 7/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2509 - accuracy: 0.8994\n",
      "Epoch 8/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2476 - accuracy: 0.8998\n",
      "Epoch 9/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2449 - accuracy: 0.9000\n",
      "Epoch 10/350\n",
      "270/270 [==============================] - 0s 811us/step - loss: 0.2463 - accuracy: 0.8989\n",
      "Epoch 11/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.2429 - accuracy: 0.8992\n",
      "Epoch 12/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2424 - accuracy: 0.8999\n",
      "Epoch 13/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2406 - accuracy: 0.8998\n",
      "Epoch 14/350\n",
      "270/270 [==============================] - 0s 848us/step - loss: 0.2389 - accuracy: 0.9009\n",
      "Epoch 15/350\n",
      "270/270 [==============================] - 0s 721us/step - loss: 0.2388 - accuracy: 0.9013\n",
      "Epoch 16/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2381 - accuracy: 0.9004\n",
      "Epoch 17/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.2366 - accuracy: 0.9014\n",
      "Epoch 18/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2366 - accuracy: 0.9007\n",
      "Epoch 19/350\n",
      "270/270 [==============================] - 0s 811us/step - loss: 0.2357 - accuracy: 0.9021\n",
      "Epoch 20/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2340 - accuracy: 0.9002\n",
      "Epoch 21/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2333 - accuracy: 0.9036\n",
      "Epoch 22/350\n",
      "270/270 [==============================] - 0s 825us/step - loss: 0.2341 - accuracy: 0.9028\n",
      "Epoch 23/350\n",
      "270/270 [==============================] - 0s 837us/step - loss: 0.2326 - accuracy: 0.9019\n",
      "Epoch 24/350\n",
      "270/270 [==============================] - 0s 736us/step - loss: 0.2323 - accuracy: 0.9022\n",
      "Epoch 25/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.2325 - accuracy: 0.9048\n",
      "Epoch 26/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2303 - accuracy: 0.9037\n",
      "Epoch 27/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2308 - accuracy: 0.9027\n",
      "Epoch 28/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2283 - accuracy: 0.9037\n",
      "Epoch 29/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2285 - accuracy: 0.9053\n",
      "Epoch 30/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2283 - accuracy: 0.9036\n",
      "Epoch 31/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2267 - accuracy: 0.9050\n",
      "Epoch 32/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2268 - accuracy: 0.9040\n",
      "Epoch 33/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2267 - accuracy: 0.9053\n",
      "Epoch 34/350\n",
      "270/270 [==============================] - 0s 829us/step - loss: 0.2255 - accuracy: 0.9043\n",
      "Epoch 35/350\n",
      "270/270 [==============================] - 0s 811us/step - loss: 0.2247 - accuracy: 0.9068\n",
      "Epoch 36/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2254 - accuracy: 0.9059\n",
      "Epoch 37/350\n",
      "270/270 [==============================] - 0s 859us/step - loss: 0.2231 - accuracy: 0.9052\n",
      "Epoch 38/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2217 - accuracy: 0.9073\n",
      "Epoch 39/350\n",
      "270/270 [==============================] - 0s 829us/step - loss: 0.2234 - accuracy: 0.9065\n",
      "Epoch 40/350\n",
      "270/270 [==============================] - 0s 844us/step - loss: 0.2221 - accuracy: 0.9088\n",
      "Epoch 41/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.2209 - accuracy: 0.9088\n",
      "Epoch 42/350\n",
      "270/270 [==============================] - 0s 814us/step - loss: 0.2212 - accuracy: 0.9086\n",
      "Epoch 43/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2208 - accuracy: 0.9077\n",
      "Epoch 44/350\n",
      "270/270 [==============================] - 0s 729us/step - loss: 0.2189 - accuracy: 0.9087\n",
      "Epoch 45/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2202 - accuracy: 0.9079\n",
      "Epoch 46/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2213 - accuracy: 0.9099\n",
      "Epoch 47/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2190 - accuracy: 0.9077\n",
      "Epoch 48/350\n",
      "270/270 [==============================] - 0s 811us/step - loss: 0.2179 - accuracy: 0.9090\n",
      "Epoch 49/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2185 - accuracy: 0.9094\n",
      "Epoch 50/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2182 - accuracy: 0.9095\n",
      "Epoch 51/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2181 - accuracy: 0.9096\n",
      "Epoch 52/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2171 - accuracy: 0.9115\n",
      "Epoch 53/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2165 - accuracy: 0.9092\n",
      "Epoch 54/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2161 - accuracy: 0.9104\n",
      "Epoch 55/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2167 - accuracy: 0.9096\n",
      "Epoch 56/350\n",
      "270/270 [==============================] - 0s 851us/step - loss: 0.2157 - accuracy: 0.9115\n",
      "Epoch 57/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2149 - accuracy: 0.9109\n",
      "Epoch 58/350\n",
      "270/270 [==============================] - 0s 825us/step - loss: 0.2166 - accuracy: 0.9089\n",
      "Epoch 59/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2144 - accuracy: 0.9093\n",
      "Epoch 60/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2146 - accuracy: 0.9099\n",
      "Epoch 61/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2152 - accuracy: 0.9104\n",
      "Epoch 62/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2135 - accuracy: 0.9108\n",
      "Epoch 63/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2121 - accuracy: 0.9116\n",
      "Epoch 64/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2135 - accuracy: 0.9106\n",
      "Epoch 65/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2137 - accuracy: 0.9108\n",
      "Epoch 66/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2124 - accuracy: 0.9123\n",
      "Epoch 67/350\n",
      "270/270 [==============================] - 0s 751us/step - loss: 0.2125 - accuracy: 0.9115\n",
      "Epoch 68/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2139 - accuracy: 0.9121\n",
      "Epoch 69/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2108 - accuracy: 0.9144\n",
      "Epoch 70/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2117 - accuracy: 0.9123\n",
      "Epoch 71/350\n",
      "270/270 [==============================] - 0s 829us/step - loss: 0.2117 - accuracy: 0.9113\n",
      "Epoch 72/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2122 - accuracy: 0.9131\n",
      "Epoch 73/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2114 - accuracy: 0.9122\n",
      "Epoch 74/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2102 - accuracy: 0.9104\n",
      "Epoch 75/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2106 - accuracy: 0.9121\n",
      "Epoch 76/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2082 - accuracy: 0.9130\n",
      "Epoch 77/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2093 - accuracy: 0.9125\n",
      "Epoch 78/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.2097 - accuracy: 0.9144\n",
      "Epoch 79/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 811us/step - loss: 0.2100 - accuracy: 0.9136\n",
      "Epoch 80/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2094 - accuracy: 0.9122\n",
      "Epoch 81/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2084 - accuracy: 0.9129\n",
      "Epoch 82/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2073 - accuracy: 0.9151\n",
      "Epoch 83/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.2073 - accuracy: 0.9144\n",
      "Epoch 84/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2073 - accuracy: 0.9145\n",
      "Epoch 85/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2087 - accuracy: 0.9155\n",
      "Epoch 86/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2060 - accuracy: 0.9160\n",
      "Epoch 87/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2060 - accuracy: 0.9146\n",
      "Epoch 88/350\n",
      "270/270 [==============================] - 0s 963us/step - loss: 0.2104 - accuracy: 0.9132\n",
      "Epoch 89/350\n",
      "270/270 [==============================] - 0s 940us/step - loss: 0.2079 - accuracy: 0.9147\n",
      "Epoch 90/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2074 - accuracy: 0.9115\n",
      "Epoch 91/350\n",
      "270/270 [==============================] - 0s 751us/step - loss: 0.2106 - accuracy: 0.9133\n",
      "Epoch 92/350\n",
      "270/270 [==============================] - 0s 725us/step - loss: 0.2064 - accuracy: 0.9154\n",
      "Epoch 93/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2061 - accuracy: 0.9176\n",
      "Epoch 94/350\n",
      "270/270 [==============================] - 0s 829us/step - loss: 0.2057 - accuracy: 0.9145\n",
      "Epoch 95/350\n",
      "270/270 [==============================] - 0s 851us/step - loss: 0.2065 - accuracy: 0.9174\n",
      "Epoch 96/350\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.9175\n",
      "Epoch 97/350\n",
      "270/270 [==============================] - 0s 896us/step - loss: 0.2040 - accuracy: 0.9181\n",
      "Epoch 98/350\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.9144\n",
      "Epoch 99/350\n",
      "270/270 [==============================] - 0s 926us/step - loss: 0.2048 - accuracy: 0.9167\n",
      "Epoch 100/350\n",
      "270/270 [==============================] - 0s 874us/step - loss: 0.2059 - accuracy: 0.9150\n",
      "Epoch 101/350\n",
      "270/270 [==============================] - 0s 985us/step - loss: 0.2048 - accuracy: 0.9176\n",
      "Epoch 102/350\n",
      "270/270 [==============================] - 0s 926us/step - loss: 0.2039 - accuracy: 0.9168\n",
      "Epoch 103/350\n",
      "270/270 [==============================] - 0s 900us/step - loss: 0.2051 - accuracy: 0.9155\n",
      "Epoch 104/350\n",
      "270/270 [==============================] - 0s 879us/step - loss: 0.2074 - accuracy: 0.9172\n",
      "Epoch 105/350\n",
      "270/270 [==============================] - 0s 829us/step - loss: 0.2035 - accuracy: 0.9160\n",
      "Epoch 106/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2054 - accuracy: 0.9160\n",
      "Epoch 107/350\n",
      "270/270 [==============================] - 0s 870us/step - loss: 0.2062 - accuracy: 0.9154\n",
      "Epoch 108/350\n",
      "270/270 [==============================] - 0s 892us/step - loss: 0.2044 - accuracy: 0.9167\n",
      "Epoch 109/350\n",
      "270/270 [==============================] - 0s 863us/step - loss: 0.2034 - accuracy: 0.9165\n",
      "Epoch 110/350\n",
      "270/270 [==============================] - 0s 907us/step - loss: 0.2071 - accuracy: 0.9158\n",
      "Epoch 111/350\n",
      "270/270 [==============================] - 0s 900us/step - loss: 0.2062 - accuracy: 0.9168\n",
      "Epoch 112/350\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.9181\n",
      "Epoch 113/350\n",
      "270/270 [==============================] - 0s 881us/step - loss: 0.2050 - accuracy: 0.9176\n",
      "Epoch 114/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2052 - accuracy: 0.9176\n",
      "Epoch 115/350\n",
      "270/270 [==============================] - 0s 721us/step - loss: 0.2082 - accuracy: 0.9172\n",
      "Epoch 116/350\n",
      "270/270 [==============================] - 0s 721us/step - loss: 0.2065 - accuracy: 0.9175\n",
      "Epoch 117/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2070 - accuracy: 0.9172\n",
      "Epoch 118/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2077 - accuracy: 0.9167\n",
      "Epoch 119/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.2094 - accuracy: 0.9146\n",
      "Epoch 120/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2064 - accuracy: 0.9201\n",
      "Epoch 121/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2050 - accuracy: 0.9188\n",
      "Epoch 122/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2063 - accuracy: 0.9188\n",
      "Epoch 123/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2074 - accuracy: 0.9173\n",
      "Epoch 124/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2064 - accuracy: 0.9181\n",
      "Epoch 125/350\n",
      "270/270 [==============================] - 0s 751us/step - loss: 0.2068 - accuracy: 0.9190\n",
      "Epoch 126/350\n",
      "270/270 [==============================] - 0s 736us/step - loss: 0.2028 - accuracy: 0.9194\n",
      "Epoch 127/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2068 - accuracy: 0.9191\n",
      "Epoch 128/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2040 - accuracy: 0.9190\n",
      "Epoch 129/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2036 - accuracy: 0.9184\n",
      "Epoch 130/350\n",
      "270/270 [==============================] - 0s 811us/step - loss: 0.2083 - accuracy: 0.9210\n",
      "Epoch 131/350\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.9212\n",
      "Epoch 132/350\n",
      "270/270 [==============================] - 0s 937us/step - loss: 0.2034 - accuracy: 0.9199\n",
      "Epoch 133/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2000 - accuracy: 0.9220\n",
      "Epoch 134/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.2032 - accuracy: 0.9176\n",
      "Epoch 135/350\n",
      "270/270 [==============================] - 0s 721us/step - loss: 0.2031 - accuracy: 0.9205\n",
      "Epoch 136/350\n",
      "270/270 [==============================] - 0s 718us/step - loss: 0.2022 - accuracy: 0.9212\n",
      "Epoch 137/350\n",
      "270/270 [==============================] - 0s 747us/step - loss: 0.2011 - accuracy: 0.9220\n",
      "Epoch 138/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.1999 - accuracy: 0.9226\n",
      "Epoch 139/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2027 - accuracy: 0.9205\n",
      "Epoch 140/350\n",
      "270/270 [==============================] - 0s 800us/step - loss: 0.2011 - accuracy: 0.9194\n",
      "Epoch 141/350\n",
      "270/270 [==============================] - 0s 747us/step - loss: 0.2032 - accuracy: 0.9211\n",
      "Epoch 142/350\n",
      "270/270 [==============================] - 0s 725us/step - loss: 0.2035 - accuracy: 0.9201\n",
      "Epoch 143/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.1993 - accuracy: 0.9199\n",
      "Epoch 144/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2015 - accuracy: 0.9209\n",
      "Epoch 145/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.2003 - accuracy: 0.9226\n",
      "Epoch 146/350\n",
      "270/270 [==============================] - 0s 729us/step - loss: 0.2057 - accuracy: 0.9214\n",
      "Epoch 147/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.1990 - accuracy: 0.9240\n",
      "Epoch 148/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2053 - accuracy: 0.9206\n",
      "Epoch 149/350\n",
      "270/270 [==============================] - 0s 736us/step - loss: 0.2018 - accuracy: 0.9201\n",
      "Epoch 150/350\n",
      "270/270 [==============================] - 0s 814us/step - loss: 0.1991 - accuracy: 0.9216\n",
      "Epoch 151/350\n",
      "270/270 [==============================] - 0s 754us/step - loss: 0.2002 - accuracy: 0.9231\n",
      "Epoch 152/350\n",
      "270/270 [==============================] - 0s 736us/step - loss: 0.1982 - accuracy: 0.9227\n",
      "Epoch 153/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.1983 - accuracy: 0.9241\n",
      "Epoch 154/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2006 - accuracy: 0.9213\n",
      "Epoch 155/350\n",
      "270/270 [==============================] - 0s 751us/step - loss: 0.2010 - accuracy: 0.9228\n",
      "Epoch 156/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2001 - accuracy: 0.9242\n",
      "Epoch 157/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 796us/step - loss: 0.1987 - accuracy: 0.9218\n",
      "Epoch 158/350\n",
      "270/270 [==============================] - 0s 703us/step - loss: 0.1967 - accuracy: 0.9240\n",
      "Epoch 159/350\n",
      "270/270 [==============================] - 0s 721us/step - loss: 0.1963 - accuracy: 0.9245\n",
      "Epoch 160/350\n",
      "270/270 [==============================] - 0s 814us/step - loss: 0.2012 - accuracy: 0.9226\n",
      "Epoch 161/350\n",
      "270/270 [==============================] - 0s 725us/step - loss: 0.2013 - accuracy: 0.9213\n",
      "Epoch 162/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2010 - accuracy: 0.9264\n",
      "Epoch 163/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.1998 - accuracy: 0.9223\n",
      "Epoch 164/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2009 - accuracy: 0.9241\n",
      "Epoch 165/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2012 - accuracy: 0.9227\n",
      "Epoch 166/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.1988 - accuracy: 0.9232\n",
      "Epoch 167/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.1991 - accuracy: 0.9247\n",
      "Epoch 168/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.1989 - accuracy: 0.9232\n",
      "Epoch 169/350\n",
      "270/270 [==============================] - 0s 848us/step - loss: 0.1985 - accuracy: 0.9239\n",
      "Epoch 170/350\n",
      "270/270 [==============================] - 0s 752us/step - loss: 0.1993 - accuracy: 0.9245\n",
      "Epoch 171/350\n",
      "270/270 [==============================] - 0s 718us/step - loss: 0.1955 - accuracy: 0.9254\n",
      "Epoch 172/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.1976 - accuracy: 0.9235\n",
      "Epoch 173/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.1998 - accuracy: 0.9226\n",
      "Epoch 174/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.1946 - accuracy: 0.9263\n",
      "Epoch 175/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.1965 - accuracy: 0.9249\n",
      "Epoch 176/350\n",
      "270/270 [==============================] - 0s 904us/step - loss: 0.1959 - accuracy: 0.9269\n",
      "Epoch 177/350\n",
      "270/270 [==============================] - 0s 822us/step - loss: 0.1999 - accuracy: 0.9247\n",
      "Epoch 178/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.1971 - accuracy: 0.9272\n",
      "Epoch 179/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.1988 - accuracy: 0.9227\n",
      "Epoch 180/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.1973 - accuracy: 0.9254\n",
      "Epoch 181/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.1994 - accuracy: 0.9225\n",
      "Epoch 182/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.1968 - accuracy: 0.9256\n",
      "Epoch 183/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.1995 - accuracy: 0.9236\n",
      "Epoch 184/350\n",
      "270/270 [==============================] - 0s 837us/step - loss: 0.2011 - accuracy: 0.9220\n",
      "Epoch 185/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.1982 - accuracy: 0.9262\n",
      "Epoch 186/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.1966 - accuracy: 0.9242\n",
      "Epoch 187/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.1954 - accuracy: 0.9243\n",
      "Epoch 188/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.1996 - accuracy: 0.9249\n",
      "Epoch 189/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.1972 - accuracy: 0.9252\n",
      "Epoch 190/350\n",
      "270/270 [==============================] - 0s 729us/step - loss: 0.1942 - accuracy: 0.9238\n",
      "Epoch 191/350\n",
      "270/270 [==============================] - 0s 729us/step - loss: 0.1964 - accuracy: 0.9206\n",
      "Epoch 192/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2020 - accuracy: 0.9218\n",
      "Epoch 193/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2108 - accuracy: 0.9197\n",
      "Epoch 194/350\n",
      "270/270 [==============================] - 0s 822us/step - loss: 0.1981 - accuracy: 0.9231\n",
      "Epoch 195/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.1964 - accuracy: 0.9241\n",
      "Epoch 196/350\n",
      "270/270 [==============================] - 0s 825us/step - loss: 0.1993 - accuracy: 0.9253\n",
      "Epoch 197/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2007 - accuracy: 0.9249\n",
      "Epoch 198/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.1967 - accuracy: 0.9230\n",
      "Epoch 199/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.1987 - accuracy: 0.9238\n",
      "Epoch 200/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2132 - accuracy: 0.9225\n",
      "Epoch 201/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.1996 - accuracy: 0.9254\n",
      "Epoch 202/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2046 - accuracy: 0.9169\n",
      "Epoch 203/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.1972 - accuracy: 0.9253\n",
      "Epoch 204/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.1995 - accuracy: 0.9242\n",
      "Epoch 205/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2029 - accuracy: 0.9248\n",
      "Epoch 206/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.1994 - accuracy: 0.9239\n",
      "Epoch 207/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.2007 - accuracy: 0.9253\n",
      "Epoch 208/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.1991 - accuracy: 0.9260\n",
      "Epoch 209/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.1996 - accuracy: 0.9243\n",
      "Epoch 210/350\n",
      "270/270 [==============================] - 0s 874us/step - loss: 0.1988 - accuracy: 0.9248\n",
      "Epoch 211/350\n",
      "270/270 [==============================] - 0s 844us/step - loss: 0.1973 - accuracy: 0.9245\n",
      "Epoch 212/350\n",
      "270/270 [==============================] - 0s 840us/step - loss: 0.1975 - accuracy: 0.9235\n",
      "Epoch 213/350\n",
      "270/270 [==============================] - 0s 863us/step - loss: 0.2031 - accuracy: 0.9233\n",
      "Epoch 214/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.1988 - accuracy: 0.9255\n",
      "Epoch 215/350\n",
      "270/270 [==============================] - 0s 718us/step - loss: 0.1983 - accuracy: 0.9206\n",
      "Epoch 216/350\n",
      "270/270 [==============================] - 0s 747us/step - loss: 0.1995 - accuracy: 0.9257\n",
      "Epoch 217/350\n",
      "270/270 [==============================] - 0s 718us/step - loss: 0.1999 - accuracy: 0.9289\n",
      "Epoch 218/350\n",
      "270/270 [==============================] - 0s 814us/step - loss: 0.1996 - accuracy: 0.9275\n",
      "Epoch 219/350\n",
      "270/270 [==============================] - 0s 725us/step - loss: 0.1982 - accuracy: 0.9258\n",
      "Epoch 220/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2006 - accuracy: 0.9241\n",
      "Epoch 221/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.1966 - accuracy: 0.9258\n",
      "Epoch 222/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.1957 - accuracy: 0.9253\n",
      "Epoch 223/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.1964 - accuracy: 0.9272\n",
      "Epoch 224/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2050 - accuracy: 0.9252\n",
      "Epoch 225/350\n",
      "270/270 [==============================] - 0s 747us/step - loss: 0.2015 - accuracy: 0.9221\n",
      "Epoch 226/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2022 - accuracy: 0.9240\n",
      "Epoch 227/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.1965 - accuracy: 0.9239\n",
      "Epoch 228/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2008 - accuracy: 0.9188\n",
      "Epoch 229/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2013 - accuracy: 0.9214\n",
      "Epoch 230/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2023 - accuracy: 0.9228\n",
      "Epoch 231/350\n",
      "270/270 [==============================] - 0s 822us/step - loss: 0.2037 - accuracy: 0.9225\n",
      "Epoch 232/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.2081 - accuracy: 0.9254\n",
      "Epoch 233/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2008 - accuracy: 0.9227\n",
      "Epoch 234/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2021 - accuracy: 0.9250\n",
      "Epoch 235/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 785us/step - loss: 0.1993 - accuracy: 0.9213\n",
      "Epoch 236/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2064 - accuracy: 0.9225\n",
      "Epoch 237/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2006 - accuracy: 0.9223\n",
      "Epoch 238/350\n",
      "270/270 [==============================] - 0s 837us/step - loss: 0.2045 - accuracy: 0.9217\n",
      "Epoch 239/350\n",
      "270/270 [==============================] - 0s 822us/step - loss: 0.2064 - accuracy: 0.9223\n",
      "Epoch 240/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2077 - accuracy: 0.9217\n",
      "Epoch 241/350\n",
      "270/270 [==============================] - 0s 829us/step - loss: 0.2060 - accuracy: 0.9195\n",
      "Epoch 242/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2091 - accuracy: 0.9174\n",
      "Epoch 243/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2015 - accuracy: 0.9208\n",
      "Epoch 244/350\n",
      "270/270 [==============================] - 0s 814us/step - loss: 0.2052 - accuracy: 0.9211\n",
      "Epoch 245/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2082 - accuracy: 0.9203\n",
      "Epoch 246/350\n",
      "270/270 [==============================] - 0s 833us/step - loss: 0.2025 - accuracy: 0.9225\n",
      "Epoch 247/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2024 - accuracy: 0.9238\n",
      "Epoch 248/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2051 - accuracy: 0.9221\n",
      "Epoch 249/350\n",
      "270/270 [==============================] - 0s 725us/step - loss: 0.2066 - accuracy: 0.9224\n",
      "Epoch 250/350\n",
      "270/270 [==============================] - 0s 736us/step - loss: 0.2104 - accuracy: 0.9206\n",
      "Epoch 251/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.4541 - accuracy: 0.9218\n",
      "Epoch 252/350\n",
      "270/270 [==============================] - 0s 777us/step - loss: 0.2094 - accuracy: 0.9181\n",
      "Epoch 253/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2126 - accuracy: 0.9185\n",
      "Epoch 254/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2066 - accuracy: 0.9216\n",
      "Epoch 255/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2076 - accuracy: 0.9227\n",
      "Epoch 256/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2174 - accuracy: 0.9210\n",
      "Epoch 257/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2053 - accuracy: 0.9211\n",
      "Epoch 258/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2131 - accuracy: 0.9217\n",
      "Epoch 259/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2113 - accuracy: 0.9225\n",
      "Epoch 260/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2153 - accuracy: 0.9197\n",
      "Epoch 261/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 2.7057 - accuracy: 0.9220\n",
      "Epoch 262/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2278 - accuracy: 0.9225\n",
      "Epoch 263/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2019 - accuracy: 0.9232\n",
      "Epoch 264/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.7277 - accuracy: 0.9199\n",
      "Epoch 265/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2112 - accuracy: 0.9198\n",
      "Epoch 266/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2143 - accuracy: 0.9203\n",
      "Epoch 267/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.4065 - accuracy: 0.9183\n",
      "Epoch 268/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.3131 - accuracy: 0.9191\n",
      "Epoch 269/350\n",
      "270/270 [==============================] - 0s 818us/step - loss: 0.2055 - accuracy: 0.9228\n",
      "Epoch 270/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2074 - accuracy: 0.9223\n",
      "Epoch 271/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2223 - accuracy: 0.9190\n",
      "Epoch 272/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2111 - accuracy: 0.9196\n",
      "Epoch 273/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.3563 - accuracy: 0.9216\n",
      "Epoch 274/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 1.2693 - accuracy: 0.9216\n",
      "Epoch 275/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2012 - accuracy: 0.9250\n",
      "Epoch 276/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2214 - accuracy: 0.9195\n",
      "Epoch 277/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 1.3768 - accuracy: 0.9218\n",
      "Epoch 278/350\n",
      "270/270 [==============================] - 0s 744us/step - loss: 0.2172 - accuracy: 0.9221\n",
      "Epoch 279/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2092 - accuracy: 0.9218\n",
      "Epoch 280/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 1.7684 - accuracy: 0.9218\n",
      "Epoch 281/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 2.1562 - accuracy: 0.9184\n",
      "Epoch 282/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2375 - accuracy: 0.9159\n",
      "Epoch 283/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 3.6363 - accuracy: 0.9173\n",
      "Epoch 284/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2166 - accuracy: 0.9165\n",
      "Epoch 285/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.3619 - accuracy: 0.9160\n",
      "Epoch 286/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2185 - accuracy: 0.9206\n",
      "Epoch 287/350\n",
      "270/270 [==============================] - 0s 744us/step - loss: 6.4561 - accuracy: 0.9169\n",
      "Epoch 288/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2145 - accuracy: 0.9163\n",
      "Epoch 289/350\n",
      "270/270 [==============================] - 0s 747us/step - loss: 0.2729 - accuracy: 0.9180\n",
      "Epoch 290/350\n",
      "270/270 [==============================] - 0s 736us/step - loss: 0.9231 - accuracy: 0.9136\n",
      "Epoch 291/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2205 - accuracy: 0.9158\n",
      "Epoch 292/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2171 - accuracy: 0.9167\n",
      "Epoch 293/350\n",
      "270/270 [==============================] - 0s 814us/step - loss: 0.2700 - accuracy: 0.9153\n",
      "Epoch 294/350\n",
      "270/270 [==============================] - 0s 885us/step - loss: 0.2164 - accuracy: 0.9179\n",
      "Epoch 295/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.2734 - accuracy: 0.9183\n",
      "Epoch 296/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2267 - accuracy: 0.9129\n",
      "Epoch 297/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2229 - accuracy: 0.9157\n",
      "Epoch 298/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2248 - accuracy: 0.9177\n",
      "Epoch 299/350\n",
      "270/270 [==============================] - 0s 718us/step - loss: 0.2342 - accuracy: 0.9144\n",
      "Epoch 300/350\n",
      "270/270 [==============================] - 0s 733us/step - loss: 0.3673 - accuracy: 0.9176\n",
      "Epoch 301/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2891 - accuracy: 0.9166\n",
      "Epoch 302/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2489 - accuracy: 0.9191\n",
      "Epoch 303/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 7.1663 - accuracy: 0.9189\n",
      "Epoch 304/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.5875 - accuracy: 0.9176\n",
      "Epoch 305/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2211 - accuracy: 0.9177\n",
      "Epoch 306/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2271 - accuracy: 0.9166\n",
      "Epoch 307/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2299 - accuracy: 0.9177\n",
      "Epoch 308/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2163 - accuracy: 0.9172\n",
      "Epoch 309/350\n",
      "270/270 [==============================] - 0s 740us/step - loss: 0.2851 - accuracy: 0.9151\n",
      "Epoch 310/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 2.1523 - accuracy: 0.9177\n",
      "Epoch 311/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2215 - accuracy: 0.9139\n",
      "Epoch 312/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2240 - accuracy: 0.9168\n",
      "Epoch 313/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 759us/step - loss: 0.2253 - accuracy: 0.9133\n",
      "Epoch 314/350\n",
      "270/270 [==============================] - 0s 759us/step - loss: 0.2253 - accuracy: 0.9145\n",
      "Epoch 315/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2232 - accuracy: 0.9180\n",
      "Epoch 316/350\n",
      "270/270 [==============================] - 0s 781us/step - loss: 0.2313 - accuracy: 0.9168\n",
      "Epoch 317/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2234 - accuracy: 0.9184\n",
      "Epoch 318/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2213 - accuracy: 0.9169\n",
      "Epoch 319/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 0.2258 - accuracy: 0.9136\n",
      "Epoch 320/350\n",
      "270/270 [==============================] - 0s 755us/step - loss: 0.2298 - accuracy: 0.9162\n",
      "Epoch 321/350\n",
      "270/270 [==============================] - 0s 747us/step - loss: 0.2469 - accuracy: 0.9180\n",
      "Epoch 322/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2236 - accuracy: 0.9130\n",
      "Epoch 323/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 13.9165 - accuracy: 0.9165\n",
      "Epoch 324/350\n",
      "270/270 [==============================] - 0s 751us/step - loss: 0.7831 - accuracy: 0.9163\n",
      "Epoch 325/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2154 - accuracy: 0.9163\n",
      "Epoch 326/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 10.4175 - accuracy: 0.9150\n",
      "Epoch 327/350\n",
      "270/270 [==============================] - 0s 744us/step - loss: 0.2199 - accuracy: 0.9168\n",
      "Epoch 328/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 0.2276 - accuracy: 0.9150\n",
      "Epoch 329/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2326 - accuracy: 0.9122\n",
      "Epoch 330/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2195 - accuracy: 0.9150\n",
      "Epoch 331/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.2168 - accuracy: 0.9179\n",
      "Epoch 332/350\n",
      "270/270 [==============================] - 0s 796us/step - loss: 0.2253 - accuracy: 0.9168\n",
      "Epoch 333/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2235 - accuracy: 0.9129\n",
      "Epoch 334/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2206 - accuracy: 0.9176\n",
      "Epoch 335/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.2631 - accuracy: 0.9019\n",
      "Epoch 336/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2455 - accuracy: 0.9009\n",
      "Epoch 337/350\n",
      "270/270 [==============================] - 0s 785us/step - loss: 0.3915 - accuracy: 0.9088\n",
      "Epoch 338/350\n",
      "270/270 [==============================] - 0s 811us/step - loss: 0.2236 - accuracy: 0.9113\n",
      "Epoch 339/350\n",
      "270/270 [==============================] - 0s 803us/step - loss: 0.3009 - accuracy: 0.9088\n",
      "Epoch 340/350\n",
      "270/270 [==============================] - 0s 807us/step - loss: 0.2365 - accuracy: 0.9051\n",
      "Epoch 341/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.2298 - accuracy: 0.9048\n",
      "Epoch 342/350\n",
      "270/270 [==============================] - 0s 766us/step - loss: 8.5478 - accuracy: 0.9109\n",
      "Epoch 343/350\n",
      "270/270 [==============================] - 0s 833us/step - loss: 0.2529 - accuracy: 0.9137\n",
      "Epoch 344/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2195 - accuracy: 0.9143\n",
      "Epoch 345/350\n",
      "270/270 [==============================] - 0s 770us/step - loss: 0.2574 - accuracy: 0.9174\n",
      "Epoch 346/350\n",
      "270/270 [==============================] - 0s 762us/step - loss: 0.2161 - accuracy: 0.9168\n",
      "Epoch 347/350\n",
      "270/270 [==============================] - 0s 773us/step - loss: 2.1251 - accuracy: 0.9160\n",
      "Epoch 348/350\n",
      "270/270 [==============================] - 0s 799us/step - loss: 0.2143 - accuracy: 0.9165\n",
      "Epoch 349/350\n",
      "270/270 [==============================] - 0s 788us/step - loss: 0.2193 - accuracy: 0.9169\n",
      "Epoch 350/350\n",
      "270/270 [==============================] - 0s 792us/step - loss: 0.4002 - accuracy: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14dde2424f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scale, y_train_onehot, epochs=350, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4090a1f",
   "metadata": {},
   "source": [
    "Now we are done with the code section, let's move on to the model export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ce78604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the model save\n",
    "import os\n",
    "from tensorflow import saved_model as SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be3e08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finalfinal\\assets\n"
     ]
    }
   ],
   "source": [
    "#actually saving the model and defining the path\n",
    "model.save(\"finalfinal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08cefb1",
   "metadata": {},
   "source": [
    "This marks the end of the main model code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
